import { Context } from 'grammy';
import { InlineKeyboard } from 'grammy';
import { LLMModel, AgentRole } from '@real-estate-bot/shared';
import { LLMService } from '../services/llm.service';
import { MODELS, MODEL_PRESETS, selectOptimalModel } from '../config/models';

export async function experimentCommand(ctx: Context) {
  const keyboard = new InlineKeyboard()
    .text('üß™ –¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π', 'test_models')
    .text('üí∞ –°—Ä–∞–≤–Ω–∏—Ç—å —Ü–µ–Ω—ã', 'compare_costs')
    .row()
    .text('üéØ –¢–µ—Å—Ç —Ä–æ–ª–µ–π', 'test_roles')
    .text('üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', 'usage_stats');

  await ctx.reply(
    'üî¨ <b>–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º</b>\n\n' +
    '–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ LLM –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.',
    {
      parse_mode: 'HTML',
      reply_markup: keyboard
    }
  );
}

export async function handleExperimentCallback(ctx: Context) {
  const data = ctx.callbackQuery?.data;
  
  switch (data) {
    case 'test_models':
      await testModels(ctx);
      break;
    case 'compare_costs':
      await compareCosts(ctx);
      break;
    case 'test_roles':
      await testRoles(ctx);
      break;
    case 'usage_stats':
      await showUsageStats(ctx);
      break;
  }
  
  await ctx.answerCallbackQuery();
}

async function testModels(ctx: Context) {
  const testPrompt = '–ù–∞–π–¥–∏ –º–Ω–µ –∫–≤–∞—Ä—Ç–∏—Ä—É –¥–ª—è –º–æ–ª–æ–¥–æ–π —Å–µ–º—å–∏ —Å —Ä–µ–±–µ–Ω–∫–æ–º, –±—é–¥–∂–µ—Ç 10 –º–ª–Ω';
  
  await ctx.reply('üîÑ –¢–µ—Å—Ç–∏—Ä—É—é —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–æ–º...\n');
  
  const models: LLMModel[] = [
    'openai/gpt-3.5-turbo',
    'anthropic/claude-3-haiku',
    'mistralai/mixtral-8x7b-instruct',
    'google/gemini-pro',
    'meta-llama/llama-3-8b-instruct'
  ];
  
  for (const model of models) {
    const llm = new LLMService('economy', { interviewer: model });
    const start = Date.now();
    
    try {
      const response = await llm.generateResponse({
        userId: ctx.from?.id.toString() || '',
        role: 'interviewer',
        history: [{ role: 'user', content: testPrompt }],
        preferences: {}
      });
      
      const time = Date.now() - start;
      const modelInfo = MODELS[model];
      
      await ctx.reply(
        `<b>üì¶ ${model}</b>\n` +
        `‚è± –í—Ä–µ–º—è: ${time}ms\n` +
        `üí∞ –¶–µ–Ω–∞: ~$${((modelInfo.inputCost + modelInfo.outputCost) / 2000).toFixed(4)}\n` +
        `üöÄ –°–∫–æ—Ä–æ—Å—Ç—å: ${modelInfo.speed}\n\n` +
        `<i>–û—Ç–≤–µ—Ç:</i>\n${response.message.substring(0, 300)}...`,
        { parse_mode: 'HTML' }
      );
      
      await new Promise(resolve => setTimeout(resolve, 1000)); // Rate limiting
    } catch (error) {
      await ctx.reply(`‚ùå –û—à–∏–±–∫–∞ —Å ${model}: ${error}`);
    }
  }
}

async function compareCosts(ctx: Context) {
  let report = 'üí∞ <b>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π</b>\n\n';
  
  const roles: AgentRole[] = ['interviewer', 'analyzer', 'explainer', 'consultant', 'negotiator'];
  
  for (const preset of ['premium', 'balanced', 'economy'] as const) {
    report += `<b>${preset.toUpperCase()}</b>\n`;
    let totalCost = 0;
    
    for (const role of roles) {
      const model = MODEL_PRESETS[preset][role];
      const info = MODELS[model];
      const avgCost = (info.inputCost + info.outputCost) / 2000; // per 1k tokens
      totalCost += avgCost;
      
      report += `${role}: ${model.split('/')[1]} (~$${avgCost.toFixed(4)})\n`;
    }
    
    report += `<b>–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ —Å–µ—Å—Å–∏—é: ~$${(totalCost * 5).toFixed(3)}</b>\n\n`;
  }
  
  await ctx.reply(report, { parse_mode: 'HTML' });
}

async function testRoles(ctx: Context) {
  const keyboard = new InlineKeyboard()
    .text('üë§ Interviewer', 'role_interviewer')
    .text('üß† Analyzer', 'role_analyzer')
    .row()
    .text('üí¨ Explainer', 'role_explainer')
    .text('üìä Consultant', 'role_consultant')
    .row()
    .text('üíº Negotiator', 'role_negotiator');
    
  await ctx.reply(
    'üé≠ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:',
    { reply_markup: keyboard }
  );
}

async function showUsageStats(ctx: Context) {
  const { LLMUsageTracker } = await import('../services/llm.service');
  const report = LLMUsageTracker.getReport();
  
  let message = 'üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM</b>\n\n';
  
  if (report.total.count === 0) {
    message += '–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏.';
  } else {
    message += `<b>–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤:</b> ${report.total.count}\n`;
    message += `<b>–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å:</b> $${report.total.cost.toFixed(4)}\n`;
    message += `<b>–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å:</b> $${report.averageCostPerCall.toFixed(4)}\n\n`;
    
    message += '<b>–ü–æ –º–æ–¥–µ–ª—è–º:</b>\n';
    for (const [model, stats] of Object.entries(report.byModel)) {
      message += `${model}: ${stats.count} –∑–∞–ø—Ä–æ—Å–æ–≤, $${stats.cost.toFixed(4)}\n`;
    }
  }
  
  await ctx.reply(message, { parse_mode: 'HTML' });
}

// Handler for role testing
export async function handleRoleTest(ctx: Context, role: AgentRole) {
  const testCases: Record<AgentRole, { role: 'user' | 'assistant', content: string }[]> = {
    interviewer: [
      { role: 'user', content: '–•–æ—á—É –∫—É–ø–∏—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É' }
    ],
    analyzer: [
      { role: 'user', content: '–°–µ–º—å—è —Å 2 –¥–µ—Ç—å–º–∏, —Ä–∞–±–æ—Ç–∞—é –≤ —Ü–µ–Ω—Ç—Ä–µ, –∂–µ–Ω–∞ –≤ –°–∫–æ–ª–∫–æ–≤–æ, –±—é–¥–∂–µ—Ç 15 –º–ª–Ω' }
    ],
    explainer: [
      { role: 'user', content: '–ü–æ—á–µ–º—É —ç—Ç–∞ –∫–≤–∞—Ä—Ç–∏—Ä–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç –º–Ω–µ?' }
    ],
    consultant: [
      { role: 'user', content: '–°—Ç–æ–∏—Ç –ª–∏ –ø–æ–∫—É–ø–∞—Ç—å –≤ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–µ –∏–ª–∏ –ª—É—á—à–µ –≤—Ç–æ—Ä–∏—á–∫–∞?' }
    ],
    negotiator: [
      { role: 'user', content: '–ö–≤–∞—Ä—Ç–∏—Ä–∞ —Å—Ç–æ–∏—Ç 12 –º–ª–Ω, –≤–∏—Å–∏—Ç 2 –º–µ—Å—è—Ü–∞, –∫–∞–∫ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å—Å—è?' }
    ]
  };
  
  const history = testCases[role];
  if (!history) return;
  
  await ctx.reply(`üé≠ –¢–µ—Å—Ç–∏—Ä—É—é —Ä–æ–ª—å: <b>${role}</b>\n\n–ó–∞–ø—Ä–æ—Å: ${history[0].content}`, { parse_mode: 'HTML' });
  
  // Test with different presets
  for (const preset of ['economy', 'balanced', 'premium'] as const) {
    const llm = new LLMService(preset);
    const model = MODEL_PRESETS[preset][role];
    
    try {
      const response = await llm.generateResponse({
        userId: ctx.from?.id.toString() || '',
        role,
        history,
        preferences: role === 'explainer' ? {
          listing: { address: '—É–ª. –ü—É—à–∫–∏–Ω–∞, –¥. 10', price: 12000000 },
          matchScore: 8.5
        } : {}
      });
      
      await ctx.reply(
        `\n<b>Preset: ${preset}</b>\n` +
        `Model: ${model}\n\n` +
        `${response.message}`,
        { parse_mode: 'HTML' }
      );
      
    } catch (error) {
      await ctx.reply(`‚ùå –û—à–∏–±–∫–∞ —Å ${preset}: ${error}`);
    }
  }
}